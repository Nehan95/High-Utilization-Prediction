{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\nagar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score,roc_curve,auc,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv file into padas data frame\n",
    "data=pd.read_csv('highUtilizationPredictionV2wco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113024, 68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data frame (number of rows, number of columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Missing values in the data\n",
    "s=pd.DataFrame(data.isnull().sum())\n",
    "s[(s>0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in above result, there are no missing values in the data frame. So, we can go ahead and split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>ELIX1</th>\n",
       "      <th>ELIX2</th>\n",
       "      <th>ELIX3</th>\n",
       "      <th>ELIX4</th>\n",
       "      <th>ELIX5</th>\n",
       "      <th>ELIX6</th>\n",
       "      <th>ELIX7</th>\n",
       "      <th>...</th>\n",
       "      <th>drugs_m4-5</th>\n",
       "      <th>drugs_m5-6</th>\n",
       "      <th>drugs_m6-7</th>\n",
       "      <th>drugs_m7-8</th>\n",
       "      <th>drugs_m8-9</th>\n",
       "      <th>drugs_m9-10</th>\n",
       "      <th>drugs_m10-11</th>\n",
       "      <th>drugs_m11-12</th>\n",
       "      <th>HighUtilizationY2</th>\n",
       "      <th>claimCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>71</td>\n",
       "      <td>PAT136597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>86</td>\n",
       "      <td>PAT119838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W</td>\n",
       "      <td>70</td>\n",
       "      <td>PAT11289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>75</td>\n",
       "      <td>PAT178745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W</td>\n",
       "      <td>77</td>\n",
       "      <td>PAT50922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  race  age patient_id  ELIX1  ELIX2  ELIX3  ELIX4  ELIX5  ELIX6  ELIX7  \\\n",
       "0    B   71  PAT136597      0      0      0      0      0      1      0   \n",
       "1    A   86  PAT119838      0      0      0      0      0      0      0   \n",
       "2    W   70   PAT11289      1      0      0      0      0      0      0   \n",
       "3    W   75  PAT178745      0      0      0      0      1      0      0   \n",
       "4    W   77   PAT50922      0      0      0      0      1      0      0   \n",
       "\n",
       "      ...      drugs_m4-5  drugs_m5-6  drugs_m6-7  drugs_m7-8  drugs_m8-9  \\\n",
       "0     ...               0           1           4           2           1   \n",
       "1     ...               0           0           0           0           0   \n",
       "2     ...               4           2           2           0           6   \n",
       "3     ...               0           0           0           0           0   \n",
       "4     ...               4           3           4           4           4   \n",
       "\n",
       "   drugs_m9-10  drugs_m10-11  drugs_m11-12  HighUtilizationY2  claimCount  \n",
       "0            3             1             1                  1         160  \n",
       "1            0             0             0                  0          24  \n",
       "2            2             1             0                  0          52  \n",
       "3            0             0             0                  0          15  \n",
       "4            3             4             4                  0          66  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the variable race into binary dummy variables\n",
    "x=pd.get_dummies(data['race'])\n",
    "newdf=pd.concat([data,x],axis=1)\n",
    "del newdf['race']\n",
    "del newdf['patient_id']\n",
    "Y=newdf['HighUtilizationY2']\n",
    "del newdf['HighUtilizationY2']\n",
    "del newdf['claimCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(newdf, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model on training data\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using the trained model\n",
    "Predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97     21158\n",
      "          1       0.61      0.09      0.15      1447\n",
      "\n",
      "avg / total       0.92      0.94      0.92     22605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report of test set\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[21077    81]\n",
      " [ 1320   127]]\n",
      "Accuracy: 0.9380225613802257\n",
      "Precision: 0.6105769230769231\n",
      "Recall: 0.08776779543883897\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrices for test set\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, Predictions))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Predictions))\n",
    "print(\"Precision:\",precision_score(y_test, Predictions))\n",
    "print(\"Recall:\",recall_score(y_test, Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score using logistic Regression:\n",
      "AUC for train Set: 0.8213823018923839\n",
      "AUC for test Set: 0.828505776755961\n"
     ]
    }
   ],
   "source": [
    "#AUC comparison for training and test sets\n",
    "print(\"AUC score using logistic Regression:\")\n",
    "#training set\n",
    "train_pred=logmodel.predict_proba(X_train)[:, 1]\n",
    "print(\"AUC for train Set:\",roc_auc_score(y_train, train_pred))\n",
    "\n",
    "#test set\n",
    "Predictions = logmodel.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC for test Set:\",roc_auc_score(y_test, Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score using Random Forest:\n",
      "AUC for train Set: 0.9985552467067205\n",
      "AUC for test Set: 0.7491143574852919\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score using Random Forest:\")\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "#training set\n",
    "rf_probs = rf.predict_proba(X_train)[:, 1]\n",
    "print(\"AUC for train Set:\",roc_auc_score(y_train, rf_probs))\n",
    "#test set\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC for test Set:\",roc_auc_score(y_test, rf_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score using Stochastic gradient descent:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for train Set: 0.5115522538388467\n",
      "AUC for test Set: 0.5122047479937205\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score using Stochastic gradient descent:\")\n",
    "sgd=SGDClassifier(loss='modified_huber')\n",
    "sgd.fit(X_train, y_train)\n",
    "#training set\n",
    "sgd_probs = sgd.predict_proba(X_train)[:, 1]\n",
    "print(\"AUC for train Set:\",roc_auc_score(y_train, sgd_probs))\n",
    "#test set\n",
    "sgd_probs = sgd.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC for test Set:\",roc_auc_score(y_test, sgd_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score using Naive Bayes:\n",
      "AUC for train Set: 0.7920435962245227\n",
      "AUC for test Set: 0.7953138701132552\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score using Naive Bayes:\")\n",
    "nb=GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "#training set\n",
    "nb_probs = nb.predict_proba(X_train)[:, 1]\n",
    "print(\"AUC for train Set:\",roc_auc_score(y_train, nb_probs))\n",
    "#test set\n",
    "nb_probs = nb.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC for test Set:\",roc_auc_score(y_test, nb_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "AUC score using logistic Regression:\n",
    "AUC for train Set: 0.8213823018923839\n",
    "AUC for test Set: 0.828505776755961\n",
    "\n",
    "AUC score using Random Forest:\n",
    "AUC for train Set: 0.9985552467067205\n",
    "AUC for test Set: 0.7491143574852919\n",
    "\n",
    "\n",
    "AUC score using Stochastic gradient descent:\n",
    "AUC for train Set: 0.5115522538388467\n",
    "AUC for test Set: 0.5122047479937205\n",
    "\n",
    "AUC score using Naive Bayes:\n",
    "AUC for train Set: 0.7920435962245227\n",
    "AUC for test Set: 0.7953138701132552\n",
    "\n",
    "From the results above, we can see that all the models excluding random forest have almost same auc scores for training and test set. Hence, we can say that logistic regression, Stochastic gradient descent and Naive bayes are not over fitting. But there is significant difference in the AUC scores of random forest models which says that random forest might be over fitting on the data. Since random forest model might be overfitting, it cannot be a good classifier model. So, excluding random forest, it is evident that logistic regression model has highest auc score among other 3 models and the model is a good classifier if the auc score is 1 or closer to 1. Hence, Logistic Regression is a better classifier as compared to other classifier since its auc score is highest of all and closest to 1, and there is no significant difference in the auc scores of training and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
